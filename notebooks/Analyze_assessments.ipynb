{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pickle\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import statsmodels.api as sm\n",
    "plt.style.use('default')\n",
    "from IPython.display import display\n",
    "\n",
    "from scartan.datasets.meta_oai import (side_code_to_str,\n",
    "                                       prefix_var_to_visit_month,\n",
    "                                       release_to_visit_month)\n",
    "from scartan.datasets.oai._assessments import (read_compose_asmts_mri,\n",
    "                                               preproc_asmts_biomediq,\n",
    "                                               preproc_asmts_chondrometrics,\n",
    "                                               read_info_proj_22,\n",
    "                                               preproc_info_proj_22)\n",
    "from scartan.various import (bland_altman_plot, cohen_d,\n",
    "                             cohen_d_var, r2, linreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_META_OAI_IMO = ('/home/egor/Workspace/proj_scartan'\n",
    "                     '/data/91_OAI_iMorphics_full_meta/meta_dynamic.csv')\n",
    "\n",
    "PATH_MRI_AS_ROOT = '/home/egor/MedData/OAI_general/MRI_Assessment_ASCII'\n",
    "PATH_MRI_AS_SQ = Path(PATH_MRI_AS_ROOT, 'Semi-Quant')\n",
    "PATH_MRI_AS_Q = Path(PATH_MRI_AS_ROOT, 'Quant')\n",
    "\n",
    "fpaths_mri_as_biomediq = [*sorted(Path(PATH_MRI_AS_Q).glob('kmri_fnih_qcart_biomediq??.txt'))]\n",
    "fpaths_mri_as_chondr = [*sorted(Path(PATH_MRI_AS_Q).glob('kmri_qcart_eckstein??.txt'))]\n",
    "\n",
    "fpath_proj_22_info = '/home/egor/MedData/OAI_general/OAI_CompleteData_ASCII/Clinical_FNIH.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix_sel(df, suffix, include=None, exclude=None):\n",
    "    if include is None:\n",
    "        include = df.columns\n",
    "    if exclude is None:\n",
    "        exclude = []\n",
    "    \n",
    "    cols_pre = df.columns\n",
    "    cols_post = [str(c) + suffix if ((c in include) and (c not in exclude)) else c\n",
    "                 for c in cols_pre]\n",
    "    out = df.copy()\n",
    "    out.columns = cols_post\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read assessment from OAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-- Project 22 info')\n",
    "df_proj_22 = read_info_proj_22(fpath_proj_22_info)\n",
    "df_proj_22_proc = preproc_info_proj_22(df_proj_22)\n",
    "\n",
    "display(df_proj_22.head())\n",
    "display(df_proj_22_proc.head())\n",
    "print(len(df_proj_22))\n",
    "print(len(df_proj_22_proc))\n",
    "\n",
    "# Standardize the dataframes, select the data from specific projects\n",
    "selectors = ['patient', 'side', 'prefix_var', 'visit']\n",
    "\n",
    "print('-- Biomediq')\n",
    "df_biomediq = read_compose_asmts_mri(fpaths_mri_as_biomediq, verbose=True)\n",
    "df_biomediq_proc = preproc_asmts_biomediq(df_biomediq, projects=('22', ))\n",
    "display(df_biomediq_proc.head())\n",
    "\n",
    "print('-- Chondrometrics')\n",
    "df_chondr = read_compose_asmts_mri(fpaths_mri_as_chondr, verbose=True)\n",
    "df_chondr_proc = preproc_asmts_chondrometrics(df_chondr, projects=('22', ))\n",
    "display(df_chondr_proc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asmts_ext_proc = dict()\n",
    "\n",
    "asmts_ext_proc[(\"oai_prj_22\", \"biomediq\")] = df_biomediq_proc\n",
    "asmts_ext_proc[(\"oai_prj_22\", \"chondr75n\")] = df_chondr_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exlude subjects from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subjects below were drawn for trainval subset of IMO, thus, used for training of the models\n",
    "exclusion_overlap = [\n",
    "    '9369649', '9539084', '9567704', '9587749', '9657464', '9663706', '9693364',\n",
    "    '9803694', '9867284', '9947240', '9992358', '9993650', '9993833',\n",
    "]\n",
    "\n",
    "# The subjects below do not have any of 00m, 12m(!), 24m assessments\n",
    "exclusion_incomplete = [\n",
    "    '9065272', '9071463', '9120059', '9135342', '9187064', '9233578', '9338479',\n",
    "    '9353017', '9444196', '9451499', '9475582', '9489123', '9504935', '9539368',\n",
    "    '9571631', '9712471', '9811840', '9904574', '9910719', '9936312'\n",
    "]\n",
    "\n",
    "for k in ((\"oai_prj_22\", \"biomediq\"), (\"oai_prj_22\", \"chondr75n\")):\n",
    "    print(k)\n",
    "    t = asmts_ext_proc[k]\n",
    "    print(\"- initial: \", len(t))\n",
    "    t = t[~t[\"patient\"].isin(exclusion_incomplete)]\n",
    "    t = t[~t[\"patient\"].isin(exclusion_overlap)]\n",
    "    print(\"- after exlcusion: \", len(t))\n",
    "    asmts_ext_proc[k] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age, sex, BMI statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(df):\n",
    "    gb_df = df.copy()\n",
    "    \n",
    "    print(\"all\")\n",
    "    tmp_all = gb_df\n",
    "    print(\"number: \", len(tmp_all))\n",
    "    display(tmp_all.loc[:, [\"age\", \"BMI\"]].describe())\n",
    "    unique, counts = np.unique(tmp_all[\"KL\"].values, return_counts=True)\n",
    "    print(\"KL: \", dict(zip(unique, counts)))\n",
    "    \n",
    "    print(\"male\")\n",
    "    tmp_male = gb_df[gb_df[\"sex\"] == \"MALE\"]\n",
    "    print(\"number: \", len(tmp_male))\n",
    "    display(tmp_male.loc[:, [\"age\", \"BMI\"]].describe())\n",
    "    unique, counts = np.unique(tmp_male[\"KL\"].values, return_counts=True)\n",
    "    print(\"KL: \", dict(zip(unique, counts)))\n",
    "    \n",
    "    print(\"female\")\n",
    "    tmp_female = gb_df[gb_df[\"sex\"] == \"FEMALE\"]\n",
    "    print(\"number: \", len(tmp_female))\n",
    "    display(tmp_female.loc[:, [\"age\", \"BMI\"]].describe())\n",
    "    unique, counts = np.unique(tmp_female[\"KL\"].values, return_counts=True)\n",
    "    print(\"KL: \", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, sex\n",
    "tmp_p = Path(\"/home/egor/MedData/OAI_general/OAI_CompleteData_ASCII/MeasInventory.csv\")\n",
    "df_tmp0 = pd.read_csv(tmp_p, sep=',', index_col=False)\n",
    "\n",
    "df_tmp0 = df_tmp0.rename({\n",
    "    'id': 'patient',\n",
    "    'V00AGE': 'age',\n",
    "    'P02SEX': 'sex',\n",
    "}, axis=1)\n",
    "df_tmp0.loc[:, 'sex'] = df_tmp0['sex'].replace(\n",
    "    {'1: Male': 'MALE', '2: Female': 'FEMALE'})\n",
    "df_tmp0 = df_tmp0.astype({\n",
    "    'patient': str,\n",
    "    'age': int,\n",
    "    'sex': str,\n",
    "})\n",
    "df_tmp0 = df_tmp0[[\"patient\", \"age\", \"sex\"]]\n",
    "\n",
    "# BMI\n",
    "tmp_p = Path(\"/home/egor/MedData/OAI_general/OAI_CompleteData_ASCII/AllClinical00.txt\")\n",
    "df_tmp1 = pd.read_csv(tmp_p, sep='|', index_col=False)\n",
    "\n",
    "df_tmp1 = df_tmp1.rename({\n",
    "    'ID': 'patient',\n",
    "    'P01BMI': 'BMI',\n",
    "}, axis=1)\n",
    "df_tmp1 = df_tmp1.astype({\n",
    "    'patient': str,\n",
    "    'BMI': float,\n",
    "})\n",
    "df_tmp1 = df_tmp1[[\"patient\", \"BMI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iMorphics\n",
    "tmp_p = Path(\"/home/egor/Workspace/proj_scartan/data/91_OAI_iMorphics_full_meta/meta_base.csv\")\n",
    "df_tmp3 = pd.read_csv(tmp_p)\n",
    "df_tmp3 = df_tmp3.astype({\n",
    "    'patient': str,\n",
    "    'KL': int,\n",
    "})\n",
    "df_tmp3 = df_tmp3.sort_values(by=[\"patient\", \"prefix_var\"], axis=0).drop_duplicates(\"patient\", keep='first')\n",
    "df_tmp3 = df_tmp3[[\"patient\", \"KL\"]]\n",
    "\n",
    "df_t = df_tmp3.copy()\n",
    "df_t = df_t.merge(df_tmp0, how=\"inner\", on=\"patient\")\n",
    "df_t = df_t.merge(df_tmp1, how=\"inner\", on=\"patient\")\n",
    "\n",
    "print(len(df_t))\n",
    "display(df_t)\n",
    "\n",
    "data_stats(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iMorphics\n",
    "tmp_p = Path(\"/home/egor/Workspace/proj_scartan/data/91_OAI_iMorphics_full_meta/meta_base.csv\")\n",
    "df_tmp3 = pd.read_csv(tmp_p)\n",
    "df_tmp3 = df_tmp3.astype({\n",
    "    'patient': str,\n",
    "    'KL': int,\n",
    "})\n",
    "df_tmp3 = df_tmp3.sort_values(by=[\"patient\", \"prefix_var\"], axis=0).drop_duplicates([\"patient\", \"prefix_var\"])\n",
    "df_tmp3 = df_tmp3[[\"patient\", \"KL\"]]\n",
    "\n",
    "df_t = df_tmp3.copy()\n",
    "df_t = df_t.merge(df_tmp0, how=\"inner\", on=\"patient\")\n",
    "df_t = df_t.merge(df_tmp1, how=\"inner\", on=\"patient\")\n",
    "\n",
    "print(len(df_t))\n",
    "display(df_t)\n",
    "\n",
    "data_stats(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FNIH Biomarkers\n",
    "tmp_p = Path(\"/home/egor/Workspace/proj_scartan/data/61_OAI_project_22_full_meta/meta_base.csv\")\n",
    "df_tmp4 = pd.read_csv(tmp_p)\n",
    "df_tmp4 = df_tmp4.astype({\n",
    "    'patient': str,\n",
    "    'KL': int,\n",
    "})\n",
    "df_tmp4 = df_tmp4.sort_values(by=[\"patient\", \"prefix_var\"], axis=0).drop_duplicates(\"patient\")\n",
    "df_tmp4 = df_tmp4[[\"patient\", \"KL\"]]\n",
    "\n",
    "df_t = df_tmp4.copy()\n",
    "df_t = df_t.merge(df_tmp0, how=\"inner\", on=\"patient\")\n",
    "df_t = df_t.merge(df_tmp1, how=\"inner\", on=\"patient\")\n",
    "\n",
    "df_t = df_t.merge(df_proj_22_proc[[\"patient\", \"GROUPTYPE\"]], how=\"inner\", on=\"patient\")\n",
    "\n",
    "print(\"- initial: \", len(df_t))\n",
    "df_t = df_t[~df_t[\"patient\"].isin(exclusion_incomplete)]\n",
    "df_t = df_t[~df_t[\"patient\"].isin(exclusion_overlap)]\n",
    "print(\"- after exlcusion: \", len(df_t))\n",
    "\n",
    "display(df_t)\n",
    "\n",
    "data_stats(df_t)\n",
    "\n",
    "for group in pd.unique(df_t[\"GROUPTYPE\"]):\n",
    "    print(f\"---- Group: {group} ----\")\n",
    "    g = df_t[df_t[\"GROUPTYPE\"] == group]\n",
    "    data_stats(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read our assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_custom_asmts(path_cache):\n",
    "    with open(path_cache, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_asmts_ours_imo(df):\n",
    "    \"\"\" \"\"\"   \n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    df_tmp.loc[:, 'visit'] = df_tmp['prefix_var'].apply(\n",
    "        lambda p: prefix_var_to_visit_month[p])\n",
    "    \n",
    "    # Assessments\n",
    "    # - volume\n",
    "    k = 'volume_total_pred'\n",
    "    df_tmp.loc[:, 'F.VC'] = df_tmp[k].apply(lambda x: x[1])\n",
    "    df_tmp.loc[:, 'LT.VC'] = df_tmp[k].apply(lambda x: x[2])\n",
    "    df_tmp.loc[:, 'MT.VC'] = df_tmp[k].apply(lambda x: x[3])\n",
    "    df_tmp.loc[:, 'P.VC'] = df_tmp[k].apply(lambda x: x[4])\n",
    "    df_tmp.loc[:, 'LM.VC'] = df_tmp[k].apply(lambda x: x[5])\n",
    "    df_tmp.loc[:, 'MM.VC'] = df_tmp[k].apply(lambda x: x[6])\n",
    "    \n",
    "    # - thickness\n",
    "    k = 'thick_local_mean_pred'\n",
    "#     k = 'dist_transf_mean_pred'\n",
    "    if k in df_tmp.columns:\n",
    "        df_tmp.loc[:, 'F.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[1])\n",
    "        df_tmp.loc[:, 'LT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[2])\n",
    "        df_tmp.loc[:, 'MT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[3])\n",
    "        df_tmp.loc[:, 'P.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[4])\n",
    "        df_tmp.loc[:, 'LM.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[5])\n",
    "        df_tmp.loc[:, 'MM.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[6])\n",
    "    \n",
    "    selection = [\n",
    "        'F.VC', 'LT.VC', 'MT.VC', 'P.VC', 'LM.VC', 'MM.VC',\n",
    "        'F.ThCcAB.MEAN', 'LT.ThCcAB.MEAN', 'MT.ThCcAB.MEAN',\n",
    "        'P.ThCcAB.MEAN', 'LM.ThCcAB.MEAN', 'MM.ThCcAB.MEAN',\n",
    "    ]\n",
    "\n",
    "    df_tmp = df_tmp[['patient', 'side', 'KL',\n",
    "                     'prefix_var', 'visit', 'release',\n",
    "                     *selection]]\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_asmts_ours_biomediq(df):\n",
    "    \"\"\" \"\"\"   \n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    df_tmp.loc[:, 'visit'] = df_tmp['prefix_var'].apply(\n",
    "        lambda p: prefix_var_to_visit_month[p])\n",
    "\n",
    "    # Assessments\n",
    "    # - volume\n",
    "    k = 'volume_total_pred'\n",
    "    df_tmp.loc[:, 'F.VC'] = df_tmp[k].apply(lambda x: x[1] + x[2])\n",
    "    df_tmp.loc[:, 'MF.VC'] = df_tmp[k].apply(lambda x: x[1])\n",
    "    df_tmp.loc[:, 'LF.VC'] = df_tmp[k].apply(lambda x: x[2])\n",
    "    df_tmp.loc[:, 'T.VC'] = df_tmp[k].apply(lambda x: x[3] + x[4])\n",
    "    df_tmp.loc[:, 'MT.VC'] = df_tmp[k].apply(lambda x: x[3])\n",
    "    df_tmp.loc[:, 'LT.VC'] = df_tmp[k].apply(lambda x: x[4])\n",
    "    df_tmp.loc[:, 'P.VC'] = df_tmp[k].apply(lambda x: x[5])\n",
    "    df_tmp.loc[:, 'M.VC'] = df_tmp[k].apply(lambda x: x[6] + x[7])\n",
    "    df_tmp.loc[:, 'MM.VC'] = df_tmp[k].apply(lambda x: x[6])\n",
    "    df_tmp.loc[:, 'LM.VC'] = df_tmp[k].apply(lambda x: x[7])\n",
    "\n",
    "    selection = [\n",
    "        'F.VC', 'MF.VC', 'LF.VC',\n",
    "        'T.VC', 'MT.VC', 'LT.VC',\n",
    "        'P.VC',\n",
    "        'M.VC', 'MM.VC', 'LM.VC',\n",
    "    ]\n",
    "\n",
    "    df_tmp = df_tmp[['patient', 'side', 'KL', 'prefix_var', 'visit', 'release',\n",
    "                     *selection]]\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_asmts_ours_chondr75n(df):\n",
    "    \"\"\" \"\"\"   \n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    df_tmp.loc[:, 'visit'] = df_tmp['prefix_var'].apply(\n",
    "        lambda p: prefix_var_to_visit_month[p])\n",
    "\n",
    "    # Assessments\n",
    "    # - volume\n",
    "    k = 'volume_total_pred'\n",
    "    df_tmp.loc[:, 'F.VC'] = df_tmp[k].apply(lambda x: np.sum(x[1:11]))\n",
    "    df_tmp.loc[:, 'LF.VC'] = df_tmp[k].apply(lambda x: np.sum(x[1:6]))\n",
    "    df_tmp.loc[:, 'cLF.VC'] = df_tmp[k].apply(lambda x: np.sum(x[2:5]))\n",
    "    df_tmp.loc[:, 'MF.VC'] = df_tmp[k].apply(lambda x: np.sum(x[6:11]))\n",
    "    df_tmp.loc[:, 'cMF.VC'] = df_tmp[k].apply(lambda x: np.sum(x[7:10]))\n",
    "    df_tmp.loc[:, 'tLF.VC'] = df_tmp[k].apply(lambda x: x[1])\n",
    "    df_tmp.loc[:, 'ccLF.VC'] = df_tmp[k].apply(lambda x: x[2])\n",
    "    df_tmp.loc[:, 'ecLF.VC'] = df_tmp[k].apply(lambda x: x[3])\n",
    "    df_tmp.loc[:, 'icLF.VC'] = df_tmp[k].apply(lambda x: x[4])\n",
    "    df_tmp.loc[:, 'pLF.VC'] = df_tmp[k].apply(lambda x: x[5])\n",
    "    df_tmp.loc[:, 'tMF.VC'] = df_tmp[k].apply(lambda x: x[6])\n",
    "    df_tmp.loc[:, 'ccMF.VC'] = df_tmp[k].apply(lambda x: x[7])\n",
    "    df_tmp.loc[:, 'ecMF.VC'] = df_tmp[k].apply(lambda x: x[8])\n",
    "    df_tmp.loc[:, 'icMF.VC'] = df_tmp[k].apply(lambda x: x[9])\n",
    "    df_tmp.loc[:, 'pMF.VC'] = df_tmp[k].apply(lambda x: x[10])\n",
    "    \n",
    "    df_tmp.loc[:, 'T.VC'] = df_tmp[k].apply(lambda x: np.sum(x[11:21]))\n",
    "    df_tmp.loc[:, 'LT.VC'] = df_tmp[k].apply(lambda x: np.sum(x[11:16]))\n",
    "    df_tmp.loc[:, 'MT.VC'] = df_tmp[k].apply(lambda x: np.sum(x[16:21]))\n",
    "    df_tmp.loc[:, 'aLT.VC'] = df_tmp[k].apply(lambda x: x[11])\n",
    "    df_tmp.loc[:, 'pLT.VC'] = df_tmp[k].apply(lambda x: x[12])\n",
    "    df_tmp.loc[:, 'cLT.VC'] = df_tmp[k].apply(lambda x: x[13])\n",
    "    df_tmp.loc[:, 'eLT.VC'] = df_tmp[k].apply(lambda x: x[14])\n",
    "    df_tmp.loc[:, 'iLT.VC'] = df_tmp[k].apply(lambda x: x[15])\n",
    "    df_tmp.loc[:, 'aMT.VC'] = df_tmp[k].apply(lambda x: x[16])\n",
    "    df_tmp.loc[:, 'pMT.VC'] = df_tmp[k].apply(lambda x: x[17])\n",
    "    df_tmp.loc[:, 'cMT.VC'] = df_tmp[k].apply(lambda x: x[18])\n",
    "    df_tmp.loc[:, 'eMT.VC'] = df_tmp[k].apply(lambda x: x[19])\n",
    "    df_tmp.loc[:, 'iMT.VC'] = df_tmp[k].apply(lambda x: x[20])\n",
    "    \n",
    "    df_tmp.loc[:, 'P.VC'] = df_tmp[k].apply(lambda x: x[21])\n",
    "    df_tmp.loc[:, 'M.VC'] = df_tmp[k].apply(lambda x: x[22] + x[23])\n",
    "    df_tmp.loc[:, 'LM.VC'] = df_tmp[k].apply(lambda x: x[22])\n",
    "    df_tmp.loc[:, 'MM.VC'] = df_tmp[k].apply(lambda x: x[23])\n",
    "    \n",
    "    # - thickness\n",
    "    k = 'thick_local_mean_pred'\n",
    "#     k = 'dist_transf_mean_pred'\n",
    "    if k in df_tmp.columns:\n",
    "        df_tmp.loc[:, 'tLF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[1])\n",
    "        df_tmp.loc[:, 'ccLF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[2])\n",
    "        df_tmp.loc[:, 'ecLF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[3])\n",
    "        df_tmp.loc[:, 'icLF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[4])\n",
    "        df_tmp.loc[:, 'pLF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[5])\n",
    "        df_tmp.loc[:, 'tMF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[6])\n",
    "        df_tmp.loc[:, 'ccMF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[7])\n",
    "        df_tmp.loc[:, 'ecMF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[8])\n",
    "        df_tmp.loc[:, 'icMF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[9])\n",
    "        df_tmp.loc[:, 'pMF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[10])\n",
    "\n",
    "        df_tmp.loc[:, 'aLT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[11])\n",
    "        df_tmp.loc[:, 'pLT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[12])\n",
    "        df_tmp.loc[:, 'cLT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[13])\n",
    "        df_tmp.loc[:, 'eLT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[14])\n",
    "        df_tmp.loc[:, 'iLT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[15])\n",
    "        df_tmp.loc[:, 'aMT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[16])\n",
    "        df_tmp.loc[:, 'pMT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[17])\n",
    "        df_tmp.loc[:, 'cMT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[18])\n",
    "        df_tmp.loc[:, 'eMT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[19])\n",
    "        df_tmp.loc[:, 'iMT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[20])\n",
    "\n",
    "    k = 'thick_local_merged_mean_pred'\n",
    "#     k = 'dist_transf_merged_mean_pred'\n",
    "    if k in df_tmp.columns:\n",
    "        df_tmp.loc[:, 'cLF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[0])\n",
    "        df_tmp.loc[:, 'cMF.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[1])\n",
    "        df_tmp.loc[:, 'LT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[2])\n",
    "        df_tmp.loc[:, 'MT.ThCcAB.MEAN'] = df_tmp[k].apply(lambda x: x[3])\n",
    "        df_tmp.loc[:, 'cLFTC.ThCcAB.MEAN'] = \\\n",
    "            df_tmp.loc[:, 'ccLF.ThCcAB.MEAN'] + df_tmp.loc[:, 'cLT.ThCcAB.MEAN']\n",
    "        df_tmp.loc[:, 'cMFTC.ThCcAB.MEAN'] = \\\n",
    "            df_tmp.loc[:, 'ccMF.ThCcAB.MEAN'] + df_tmp.loc[:, 'cMT.ThCcAB.MEAN']\n",
    "        df_tmp.loc[:, 'LFTC.ThCcAB.MEAN'] = \\\n",
    "            df_tmp.loc[:, 'cLF.ThCcAB.MEAN'] + df_tmp.loc[:, 'LT.ThCcAB.MEAN']\n",
    "        df_tmp.loc[:, 'MFTC.ThCcAB.MEAN'] = \\\n",
    "            df_tmp.loc[:, 'cMF.ThCcAB.MEAN'] + df_tmp.loc[:, 'MT.ThCcAB.MEAN']\n",
    "\n",
    "    # NOTICE: Rename cAB to tAB for code convenience in comparing to Chondrometrics\n",
    "    for c_from in df_tmp.columns:\n",
    "        if '.ThCcAB.' in c_from:\n",
    "            c_to = c_from.replace('.ThCcAB.', '.ThCtAB.')\n",
    "            df_tmp.loc[:, c_to] = df_tmp[c_from]\n",
    "    \n",
    "    selection = [\n",
    "        'F.VC', 'LF.VC', 'MF.VC', 'cLF.VC', 'cMF.VC',\n",
    "        'tLF.VC', 'ccLF.VC', 'ecLF.VC', 'icLF.VC', 'pLF.VC',\n",
    "        'tMF.VC', 'ccMF.VC', 'ecMF.VC', 'icMF.VC', 'pMF.VC',\n",
    "        'T.VC', 'LT.VC', 'MT.VC',\n",
    "        'aLT.VC', 'pLT.VC', 'cLT.VC', 'eLT.VC', 'iLT.VC',\n",
    "        'aMT.VC', 'pMT.VC', 'cMT.VC', 'eMT.VC', 'iMT.VC',\n",
    "        'P.VC', 'M.VC', 'LM.VC', 'MM.VC',\n",
    "        \n",
    "        'aLT.ThCcAB.MEAN', 'iLT.ThCcAB.MEAN', 'cLT.ThCcAB.MEAN', 'pLT.ThCcAB.MEAN', 'eLT.ThCcAB.MEAN',\n",
    "        'aMT.ThCcAB.MEAN', 'iMT.ThCcAB.MEAN', 'cMT.ThCcAB.MEAN', 'pMT.ThCcAB.MEAN', 'eMT.ThCcAB.MEAN',\n",
    "        \n",
    "        'tLF.ThCcAB.MEAN', 'pLF.ThCcAB.MEAN', 'ecLF.ThCcAB.MEAN', 'ccLF.ThCcAB.MEAN', 'icLF.ThCcAB.MEAN',\n",
    "        'tMF.ThCcAB.MEAN', 'pMF.ThCcAB.MEAN', 'ecMF.ThCcAB.MEAN', 'ccMF.ThCcAB.MEAN', 'icMF.ThCcAB.MEAN',\n",
    "        \n",
    "        'cLF.ThCcAB.MEAN', 'LT.ThCcAB.MEAN', 'cLFTC.ThCcAB.MEAN', 'LFTC.ThCcAB.MEAN',\n",
    "        'cMF.ThCcAB.MEAN', 'MT.ThCcAB.MEAN', 'cMFTC.ThCcAB.MEAN', 'MFTC.ThCcAB.MEAN',\n",
    "        'aLT.ThCtAB.MEAN', 'iLT.ThCtAB.MEAN', 'cLT.ThCtAB.MEAN', 'pLT.ThCtAB.MEAN', 'eLT.ThCtAB.MEAN',\n",
    "        'aMT.ThCtAB.MEAN', 'iMT.ThCtAB.MEAN', 'cMT.ThCtAB.MEAN', 'pMT.ThCtAB.MEAN', 'eMT.ThCtAB.MEAN',\n",
    "        \n",
    "        'tLF.ThCtAB.MEAN', 'pLF.ThCtAB.MEAN', 'ecLF.ThCtAB.MEAN', 'ccLF.ThCtAB.MEAN', 'icLF.ThCtAB.MEAN',\n",
    "        'tMF.ThCtAB.MEAN', 'pMF.ThCtAB.MEAN', 'ecMF.ThCtAB.MEAN', 'ccMF.ThCtAB.MEAN', 'icMF.ThCtAB.MEAN',\n",
    "        \n",
    "        'cLF.ThCtAB.MEAN', 'LT.ThCtAB.MEAN', 'cLFTC.ThCtAB.MEAN', 'LFTC.ThCtAB.MEAN',\n",
    "        'cMF.ThCtAB.MEAN', 'MT.ThCtAB.MEAN', 'cMFTC.ThCtAB.MEAN', 'MFTC.ThCtAB.MEAN',\n",
    "    ]\n",
    "\n",
    "    df_tmp = df_tmp[['patient', 'side', 'KL', 'prefix_var', 'visit', 'release',\n",
    "                     *selection]]\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asmts_ours = dict()  # experiment , dataset , atlas , kind\n",
    "\n",
    "# Segmentation SotA\n",
    "asmts_ours[('20190720_0001', 'oai_imo', 'imo', 'paired')] = None\n",
    "\n",
    "# Comparison SotA\n",
    "asmts_ours[('20190720_0001', 'oai_prj_22', 'biomediq', 'single')] = None\n",
    "asmts_ours[('20190720_0001', 'oai_prj_22', 'chondr75n', 'single')] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in asmts_ours.keys():\n",
    "    experiment, dataset, atlas, kind = k\n",
    "    \n",
    "    path_results = '/home/egor/Workspace/proj_scartan/results/'\n",
    "    \n",
    "    path_cache = Path(\n",
    "        path_results,\n",
    "        experiment,\n",
    "        f'logs_{dataset}_test',\n",
    "        f'cache_{dataset}_test_{atlas}_volumew_{kind}.pkl')\n",
    "\n",
    "    asmts_ours[k] = read_custom_asmts(path_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iMoprhics -- Analysis of segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess. Segmentation assessment\n",
    "asmts_pred_proc = dict()\n",
    "asmts_true_proc = dict()\n",
    "\n",
    "k = ('20190720_0001', 'oai_imo', 'imo', 'paired')\n",
    "df_tmp = asmts_ours[k].copy()\n",
    "asmts_pred_proc[k] = preproc_asmts_ours_imo(df_tmp)\n",
    "# preproc_asmts_... is implemented for ..._pred only\n",
    "df_tmp = asmts_ours[k].copy()\n",
    "df_tmp.loc[:, 'volume_total_pred'] = df_tmp['volume_total_true']\n",
    "df_tmp.loc[:, 'thick_local_mean_pred'] = df_tmp['thick_local_mean_true']\n",
    "df_tmp.loc[:, 'dist_transf_mean_pred'] = df_tmp['dist_transf_mean_true']\n",
    "asmts_true_proc[k] = preproc_asmts_ours_imo(df_tmp)\n",
    "\n",
    "k = ('20190720_0001', 'oai_imo', 'chondr75n', 'paired')\n",
    "df_tmp = asmts_ours[k].copy()\n",
    "asmts_pred_proc[k] = preproc_asmts_ours_chondr75n(df_tmp)\n",
    "# preproc_asmts_... is implemented for ..._pred only\n",
    "df_tmp = asmts_ours[k].copy()\n",
    "df_tmp.loc[:, 'volume_total_pred'] = df_tmp['volume_total_true']\n",
    "df_tmp.loc[:, 'thick_local_mean_pred'] = df_tmp['thick_local_mean_true']\n",
    "df_tmp.loc[:, 'dist_transf_mean_pred'] = df_tmp['dist_transf_mean_true']\n",
    "asmts_true_proc[k] = preproc_asmts_ours_chondr75n(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze our segmentation in relation to the reference. OAI iMorphics\n",
    "path_out = Path('/home/egor/Workspace/proj_scartan/results/t/0_segm_imo')\n",
    "path_out.mkdir(exist_ok=True)\n",
    "\n",
    "# k = ('20190720_0001', 'oai_imo', 'segm', 'paired')\n",
    "k = ('20190720_0001', 'oai_imo', 'imo', 'paired')\n",
    "# k = ('20190720_0001', 'oai_imo', 'chondr75n', 'paired')\n",
    "# k = ('20190720_0001', 'oai_prj_22', 'chondr75n', 'single')\n",
    "\n",
    "feature_codes = (\n",
    "    ## segm\n",
    "#     'F.VC', 'T.VC', 'P.VC', 'M.VC',\n",
    "#     'F.ThCcAB.MEAN', 'T.ThCcAB.MEAN', 'P.ThCcAB.MEAN', 'M.ThCcAB.MEAN',\n",
    "    \n",
    "    ## imo\n",
    "    'F.VC', 'LT.VC', 'MT.VC', 'P.VC', 'LM.VC', 'MM.VC',\n",
    "    'F.ThCcAB.MEAN', 'LT.ThCcAB.MEAN', 'MT.ThCcAB.MEAN',\n",
    "    'P.ThCcAB.MEAN', 'LM.ThCcAB.MEAN', 'MM.ThCcAB.MEAN',\n",
    "    \n",
    "    ## pseudo-chondr\n",
    "#     'tLF.VC', 'ecLF.VC', 'ccLF.VC', 'icLF.VC', 'pLF.VC',\n",
    "#     'tMF.VC', 'ecMF.VC', 'ccMF.VC', 'icMF.VC', 'pMF.VC',\n",
    "#     'aLT.VC', 'pLT.VC', 'cLT.VC', 'eLT.VC', 'iLT.VC',\n",
    "#     'aMT.VC', 'pMT.VC', 'cMT.VC', 'eMT.VC', 'iMT.VC',\n",
    "    \n",
    "#     'tLF.ThCcAB.MEAN', 'ecLF.ThCcAB.MEAN', 'ccLF.ThCcAB.MEAN', 'icLF.ThCcAB.MEAN', 'pLF.ThCcAB.MEAN',\n",
    "#     'tMF.ThCcAB.MEAN', 'ecMF.ThCcAB.MEAN', 'ccMF.ThCcAB.MEAN', 'icMF.ThCcAB.MEAN', 'pMF.ThCcAB.MEAN',\n",
    "    \n",
    "#     'aLT.ThCcAB.MEAN', 'iLT.ThCcAB.MEAN', 'cLT.ThCcAB.MEAN', 'pLT.ThCcAB.MEAN', 'eLT.ThCcAB.MEAN',\n",
    "#     'aMT.ThCcAB.MEAN', 'iMT.ThCcAB.MEAN', 'cMT.ThCcAB.MEAN', 'pMT.ThCcAB.MEAN', 'eMT.ThCcAB.MEAN',\n",
    "    \n",
    "    ## chondr\n",
    "#     'cLF.VC', 'cMF.VC',\n",
    "#     'LT.VC', 'MT.VC',\n",
    "#     'cLF.ThCcAB.MEAN', 'ecLF.ThCcAB.MEAN', 'ccLF.ThCcAB.MEAN', 'icLF.ThCcAB.MEAN',\n",
    "#     'cMF.ThCcAB.MEAN', 'ecMF.ThCcAB.MEAN', 'ccMF.ThCcAB.MEAN', 'icMF.ThCcAB.MEAN',\n",
    "#     'aLT.ThCcAB.MEAN', 'iLT.ThCcAB.MEAN', 'cLT.ThCcAB.MEAN', 'pLT.ThCcAB.MEAN', 'eLT.ThCcAB.MEAN',\n",
    "#     'aMT.ThCcAB.MEAN', 'iMT.ThCcAB.MEAN', 'cMT.ThCcAB.MEAN', 'pMT.ThCcAB.MEAN', 'eMT.ThCcAB.MEAN',\n",
    ")\n",
    "for feature_code in feature_codes:\n",
    "\n",
    "    df_plot = pd.DataFrame.from_dict({\n",
    "        'pred': asmts_pred_proc[k][feature_code],\n",
    "        'true': asmts_true_proc[k][feature_code],\n",
    "        'side': asmts_pred_proc[k]['side'],\n",
    "    })\n",
    "    \n",
    "    plot_kws = {'kind': 'reg',\n",
    "                'stat_func': r2, 'height': 7}\n",
    "    g = sns.jointplot(x='pred', y='true', data=df_plot, **plot_kws,\n",
    "                      joint_kws={'robust': True})\n",
    "    \n",
    "    if '.VC' in feature_code:\n",
    "        g.set_axis_labels(\"Ours (mm^3)\", \"Reference (mm^3)\")\n",
    "    elif '.ThC' in feature_code:\n",
    "        g.set_axis_labels(\"Ours (mm)\", \"Reference (mm)\")\n",
    "    else:\n",
    "        print('Unhandled feature code')\n",
    "        break\n",
    "        \n",
    "#     plt.axis('equal')\n",
    "    plt.title(feature_code)\n",
    "\n",
    "    fname_out = f'{feature_code}_joint.png'\n",
    "    fpath_out = Path(path_out, fname_out)\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    plt.savefig(fpath_out)\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(1)\n",
    "    bland_altman_plot(df_plot['pred'], df_plot['true'],\n",
    "                      sd_limit=1.96,\n",
    "                      ax=axes,\n",
    "                      scatter_kws={'s': 3},\n",
    "                      mean_line_kws=None,\n",
    "                      limit_lines_kws=None)\n",
    "#     plt.axis('equal')\n",
    "    plt.title(feature_code)\n",
    "\n",
    "    fname_out = f'{feature_code}_bland_altman.png'\n",
    "    fpath_out = Path(path_out, fname_out)\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    plt.savefig(fpath_out)\n",
    "    plt.close()\n",
    "    \n",
    "    m1 = df_plot['pred']\n",
    "    m2 = df_plot['true']\n",
    "    means = np.mean([m1, m2], axis=0)\n",
    "    diffs = m1 - m2\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs, axis=0)\n",
    "    \n",
    "    print(feature_code,\n",
    "          r2(df_plot['pred'], df_plot['true']),\n",
    "          np.round(-1.96 * std_diff + mean_diff, 3),\n",
    "          np.round(mean_diff, 3),\n",
    "          np.round(1.96 * std_diff + mean_diff, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNIH Biom-s -- Comparison to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess. Compartmentalization\n",
    "selectors = ['patient', 'side', 'prefix_var', 'visit']\n",
    "\n",
    "asmts_ours_proc = dict()\n",
    "\n",
    "k = ('20190720_0001', 'oai_prj_22', 'biomediq', 'single')\n",
    "asmts_ours_proc[k] = preproc_asmts_ours_biomediq(asmts_ours[k])\n",
    "\n",
    "k = ('20190720_0001', 'oai_prj_22', 'chondr75n', 'single')\n",
    "asmts_ours_proc[k] = preproc_asmts_ours_chondr75n(asmts_ours[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: Temporary! For extension of analysis only\n",
    "k_ext = ('oai_prj_22', 'chondr75n')\n",
    "asmts_ext_proc[k_ext]\n",
    "\n",
    "for field_i, field_o in (\n",
    "    (\"LT.ThCcAB.MEAN\", \"LT.ThCtAB.MEAN\"),\n",
    "    (\"MT.ThCcAB.MEAN\", \"MT.ThCtAB.MEAN\"),\n",
    "    (\"cLF.ThCcAB.MEAN\", \"cLF.ThCtAB.MEAN\"),\n",
    "    (\"cMF.ThCcAB.MEAN\", \"cMF.ThCtAB.MEAN\"),\n",
    "):\n",
    "    asmts_ext_proc[k_ext].loc[:, field_o] = asmts_ext_proc[k_ext][field_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract common measurements\n",
    "selectors = ['patient', 'side', 'prefix_var', 'visit']\n",
    "\n",
    "asmts_compare = dict()\n",
    "\n",
    "k_ours = ('20190720_0001', 'oai_prj_22', 'biomediq', 'single')\n",
    "k_ext = ('oai_prj_22', 'biomediq')\n",
    "asmts_compare[('ours', 'biomediq')] = asmts_ours_proc[k_ours].merge(\n",
    "    asmts_ext_proc[k_ext], on=selectors,\n",
    "    how='inner', suffixes=('_ours', '_biomediq'))\n",
    "\n",
    "k_ours = ('20190720_0001', 'oai_prj_22', 'chondr75n', 'single')\n",
    "k_ext = ('oai_prj_22', 'chondr75n')\n",
    "asmts_compare[('ours', 'chondr75n')] = asmts_ours_proc[k_ours].merge(\n",
    "    asmts_ext_proc[k_ext], on=selectors,\n",
    "    how='inner', suffixes=('_ours', '_chondr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Biomediq\n",
    "path_out = Path('/home/egor/Workspace/proj_scartan/results/t/0j_biomediq_segm')\n",
    "path_out.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "feature_codes = (\n",
    "    'F.VC', 'LF.VC', 'MF.VC', \n",
    "    'LT.VC', 'MT.VC',\n",
    "    'P.VC',\n",
    "    'LM.VC', 'MM.VC'\n",
    ")\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "df_tmp = asmts_compare[('ours', 'biomediq')]\n",
    "\n",
    "for feature_code in feature_codes:    \n",
    "\n",
    "    df_plot = pd.DataFrame.from_dict({\n",
    "        'ours': df_tmp[f'{feature_code}_ours'],\n",
    "        'biomediq': df_tmp[f'{feature_code}_biomediq'],\n",
    "        'side': df_tmp['side'],\n",
    "    })\n",
    "    \n",
    "    if True:\n",
    "#     if False:\n",
    "        g = sns.jointplot(x='ours', y='biomediq', data=df_plot,\n",
    "                          kind='reg', stat_func=r2,\n",
    "                          height=7)\n",
    "\n",
    "        if \".VC\" in feature_code:\n",
    "            g.set_axis_labels(\"Ours (mm^3)\", \"Biomediq (mm^3)\")\n",
    "        elif \".ThC\" in feature_code:\n",
    "            g.set_axis_labels(\"Ours (mm)\", \"Biomediq (mm)\")\n",
    "            \n",
    "        if \".VC\" in feature_code:\n",
    "            plt.ticklabel_format(style='sci', axis='both', scilimits=(3,3))\n",
    "\n",
    "        plt.title(feature_code)\n",
    "\n",
    "        fname_out = f\"{feature_code}.png\"\n",
    "        fpath_out = Path(path_out, fname_out)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fpath_out)\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    if True:\n",
    "#     if False:\n",
    "        fig, axes = plt.subplots()\n",
    "    \n",
    "        if \".VC\" in feature_code:\n",
    "            xlabel = \"Means (mm^3)\"\n",
    "            ylabel = \"Difference (mm^3)\"\n",
    "        elif \".ThC\" in feature_code:\n",
    "            xlabel = \"Means (mm)\"\n",
    "            ylabel = \"Difference (mm)\"\n",
    "            \n",
    "        bland_altman_plot(df_plot['ours'], df_plot['biomediq'],\n",
    "                          sd_limit=1.96,\n",
    "                          ax=axes,\n",
    "                          scatter_kws={'s': 3},\n",
    "                          mean_line_kws=None,\n",
    "                          limit_lines_kws=None,\n",
    "                          xlabel=xlabel,\n",
    "                          ylabel=ylabel,\n",
    "                         )\n",
    "        \n",
    "        if \".VC\" in feature_code:\n",
    "            plt.ticklabel_format(style='sci', axis='both', scilimits=(3,3))\n",
    "        \n",
    "        plt.title(feature_code.replace(\"tAB\", \"\").replace(\".MEAN\", \"\"))\n",
    "\n",
    "        fname_out = f'{feature_code}_bland_altman.png'\n",
    "        fpath_out = Path(path_out, fname_out)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fpath_out)\n",
    "\n",
    "    # Textual\n",
    "    m1 = df_plot['ours']\n",
    "    m2 = df_plot['biomediq']\n",
    "    \n",
    "    means = np.mean([m1, m2], axis=0)\n",
    "    diffs = m1 - m2\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs, axis=0)\n",
    "    \n",
    "    regr = linreg(m1, m2)\n",
    "    \n",
    "    print(\n",
    "        feature_code, ',',\n",
    "        np.round(-1.96 * std_diff + mean_diff, 3), ',',\n",
    "        np.round(mean_diff, 3), ',',\n",
    "        np.round(1.96 * std_diff + mean_diff, 3), ',',\n",
    "        f\"{np.mean(m2):.3f}\",\n",
    "        f\"{regr['r2']:.3f}\",\n",
    "        f\"{regr['pvalue']:.3f}\",\n",
    "        f\"{np.sqrt(regr['r2']):.3f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Chondrometrics\n",
    "path_out = Path('/home/egor/Workspace/proj_scartan/results/t/0j_chondr_segm')\n",
    "path_out.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# feature_codes = (\n",
    "#     'cLF.VC', 'LT.VC', 'cMF.VC', 'MT.VC',\n",
    "    \n",
    "#     'LFTC.ThCtAB.MEAN', 'cLFTC.ThCtAB.MEAN', 'cLF.ThCtAB.MEAN',\n",
    "#     'ecLF.ThCtAB.MEAN', 'ccLF.ThCtAB.MEAN', 'icLF.ThCtAB.MEAN',\n",
    "#     'LT.ThCtAB.MEAN',\n",
    "#     'aLT.ThCtAB.MEAN', 'eLT.ThCtAB.MEAN', 'cLT.ThCtAB.MEAN', 'iLT.ThCtAB.MEAN', 'pLT.ThCtAB.MEAN', \n",
    "    \n",
    "#     'MFTC.ThCtAB.MEAN', 'cMFTC.ThCtAB.MEAN', 'cMF.ThCtAB.MEAN',\n",
    "#     'ecMF.ThCtAB.MEAN', 'ccMF.ThCtAB.MEAN', 'icMF.ThCtAB.MEAN',\n",
    "#     'MT.ThCtAB.MEAN',\n",
    "#     'aMT.ThCtAB.MEAN', 'eMT.ThCtAB.MEAN', 'cMT.ThCtAB.MEAN', 'iMT.ThCtAB.MEAN', 'pMT.ThCtAB.MEAN',\n",
    "# )\n",
    "feature_codes = (\n",
    "    'cLF.ThCtAB.MEAN', 'LT.ThCtAB.MEAN',\n",
    "    'cMF.ThCtAB.MEAN', 'MT.ThCtAB.MEAN',\n",
    ")\n",
    "# feature_codes = (\n",
    "#     'LT.VC', 'MT.VC'\n",
    "# )\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "df_tmp = asmts_compare[('ours', 'chondr75n')]\n",
    "\n",
    "df_tmp.head()\n",
    "\n",
    "for feature_code in feature_codes:\n",
    "    df_plot = pd.DataFrame.from_dict({\n",
    "        'ours': df_tmp[f'{feature_code}_ours'],\n",
    "        'chondr': df_tmp[f'{feature_code}_chondr'],\n",
    "        'side': df_tmp['side'],\n",
    "    })\n",
    "    \n",
    "    if True:\n",
    "#     if False:\n",
    "        g = sns.jointplot(x='ours', y='chondr', data=df_plot,\n",
    "                          kind=\"reg\", stat_func=r2,\n",
    "                          height=7)   \n",
    "\n",
    "        if \".VC\" in feature_code:\n",
    "            g.set_axis_labels(\"Ours (mm^3)\", \"Chondrometrics (mm^3)\")\n",
    "        elif \".ThC\" in feature_code:\n",
    "            g.set_axis_labels(\"Ours (mm)\", \"Chondrometrics (mm)\")\n",
    "            \n",
    "        if \".VC\" in feature_code:\n",
    "            plt.ticklabel_format(style='sci', axis='both', scilimits=(3,3))\n",
    "\n",
    "        plt.title(feature_code)\n",
    "\n",
    "        fname_out = f'{feature_code}.png'\n",
    "        fpath_out = Path(path_out, fname_out)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fpath_out)\n",
    "        plt.close()\n",
    "#         plt.show()\n",
    "    \n",
    "    if True:\n",
    "#     if False:\n",
    "        fig, axes = plt.subplots(1)\n",
    "    \n",
    "        if \".VC\" in feature_code:\n",
    "            xlabel = \"Means (mm^3)\"\n",
    "            ylabel = \"Difference (mm^3)\"\n",
    "        elif \".ThC\" in feature_code:\n",
    "            xlabel = \"Means (mm)\"\n",
    "            ylabel = \"Difference (mm)\"\n",
    "    \n",
    "        bland_altman_plot(df_plot['ours'], df_plot['chondr'],\n",
    "                          sd_limit=1.96,\n",
    "                          ax=axes,\n",
    "                          scatter_kws={'s': 2},\n",
    "                          mean_line_kws=None,\n",
    "                          limit_lines_kws=None,\n",
    "                          xlabel=xlabel,\n",
    "                          ylabel=ylabel,\n",
    "                         )\n",
    "        \n",
    "        if \".VC\" in feature_code:\n",
    "            plt.ticklabel_format(style='sci', axis='both', scilimits=(3,3))\n",
    "\n",
    "        plt.title(feature_code.replace(\"tAB\", \"\").replace(\".MEAN\", \"\"))\n",
    "\n",
    "        fname_out = f'{feature_code}_bland_altman.png'\n",
    "        fpath_out = Path(path_out, fname_out)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fpath_out)\n",
    "        plt.close()\n",
    "#         plt.show()\n",
    "    \n",
    "    # Textual\n",
    "    m1 = df_plot['ours']\n",
    "    m2 = df_plot['chondr']\n",
    "    \n",
    "    means = np.mean([m1, m2], axis=0)\n",
    "    diffs = m1 - m2\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs, axis=0)\n",
    "    \n",
    "    regr = linreg(m1, m2)\n",
    "    \n",
    "    print(\n",
    "        feature_code, ',',\n",
    "        np.round(-1.96 * std_diff + mean_diff, 3), ',',\n",
    "        np.round(mean_diff, 3), ',',\n",
    "        np.round(1.96 * std_diff + mean_diff, 3), ',',\n",
    "        f\"{np.mean(m2):.3f}\",\n",
    "        f\"{regr['r2']:.3f}\",\n",
    "        f\"{regr['pvalue']:.3f}\",\n",
    "        f\"{np.sqrt(regr['r2']):.3f}\",\n",
    "    )\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNIH Biomarkers -- Comparison of effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess. Compartmentalization\n",
    "selectors = ['patient', 'side', 'prefix_var', 'visit']\n",
    "\n",
    "asmts_ours_proc = dict()\n",
    "\n",
    "k = ('20190720_0001', 'oai_prj_22', 'biomediq', 'single')\n",
    "asmts_ours_proc[k] = preproc_asmts_ours_biomediq(asmts_ours[k])\n",
    "\n",
    "k = ('20190720_0001', 'oai_prj_22', 'chondr75n', 'single')\n",
    "asmts_ours_proc[k] = preproc_asmts_ours_chondr75n(asmts_ours[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract common measurements\n",
    "selectors = ['patient', 'side', 'prefix_var', 'visit']\n",
    "\n",
    "asmts_compare = dict()\n",
    "\n",
    "k_ours = ('20190720_0001', 'oai_prj_22', 'biomediq', 'single')\n",
    "k_ext = ('oai_prj_22', 'biomediq')\n",
    "asmts_compare[('ours', 'biomediq')] = asmts_ours_proc[k_ours].merge(\n",
    "    asmts_ext_proc[k_ext], on=selectors,\n",
    "    how='inner', suffixes=('_ours', '_biomediq'))\n",
    "\n",
    "k_ours = ('20190720_0001', 'oai_prj_22', 'chondr75n', 'single')\n",
    "k_ext = ('oai_prj_22', 'chondr75n')\n",
    "asmts_compare[('ours', 'chondr75n')] = asmts_ours_proc[k_ours].merge(\n",
    "    asmts_ext_proc[k_ext], on=selectors,\n",
    "    how='inner', suffixes=('_ours', '_chondr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ext = ('oai_prj_22', 'chondr75n')\n",
    "len(asmts_ext_proc[k_ext][\"cLF.ThCcAB.MEAN\"] == asmts_ext_proc[k_ext][\"cLF.ThCtAB.MEAN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixin the project info\n",
    "selectors = ['patient', 'side']\n",
    "\n",
    "k = ('ours', 'biomediq')\n",
    "asmts_compare[k] = asmts_compare[k].merge(\n",
    "    df_proj_22_proc, on=selectors,\n",
    "    how='left', suffixes=('', '_proj'))\n",
    "\n",
    "k = ('ours', 'chondr75n')\n",
    "asmts_compare[k] = asmts_compare[k].merge(\n",
    "    df_proj_22_proc, on=selectors,\n",
    "    how='left', suffixes=('', '_proj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_code_to_str = {\n",
    "    1: 'JSL & Pain Prog.',\n",
    "    2: 'JSL Prog.',\n",
    "    3: 'Pain Prog.',\n",
    "    4: 'Non-Prog.',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if some cases are with incomplete assessments\n",
    "for gn, gdf in df_tmp.groupby(['patient', 'side']):\n",
    "    if len(gdf) < 3:\n",
    "        print(f\"'{gn[0]}'\")\n",
    "#         display(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds ratio\n",
    "\n",
    "# INFO: Choose one\n",
    "# analysis = (\"biomediq\", \"\")\n",
    "# analysis = (\"chondr\", \"elastic_lt\")\n",
    "analysis = (\"chondr\", \"elastic_dt\")\n",
    "\n",
    "\n",
    "if analysis[0] == \"biomediq\":\n",
    "    k = ('ours', 'biomediq')\n",
    "elif analysis[0] == \"chondr\":\n",
    "    k = ('ours', 'chondr75n')\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "df_tmp = asmts_compare[k]\n",
    "\n",
    "if analysis[0] == \"biomediq\":\n",
    "    feature_codes = (\n",
    "        'F.VC', 'LF.VC', 'MF.VC',\n",
    "        'LT.VC', 'MT.VC',\n",
    "        'P.VC',\n",
    "        'LM.VC', 'MM.VC',\n",
    "    )\n",
    "elif analysis[0] == \"chondr\":\n",
    "    feature_codes = (\n",
    "    'cLF.VC', 'cMF.VC',\n",
    "    'LT.VC', 'MT.VC',\n",
    "    'ecLF.ThCtAB.MEAN', 'ccLF.ThCtAB.MEAN', 'icLF.ThCtAB.MEAN',\n",
    "    'ecMF.ThCtAB.MEAN', 'ccMF.ThCtAB.MEAN', 'icMF.ThCtAB.MEAN',\n",
    "    'aLT.ThCtAB.MEAN', 'iLT.ThCtAB.MEAN', 'cLT.ThCtAB.MEAN', 'pLT.ThCtAB.MEAN', 'eLT.ThCtAB.MEAN',\n",
    "    'aMT.ThCtAB.MEAN', 'iMT.ThCtAB.MEAN', 'cMT.ThCtAB.MEAN', 'pMT.ThCtAB.MEAN', 'eMT.ThCtAB.MEAN',\n",
    "    'cLF.ThCtAB.MEAN', 'LT.ThCtAB.MEAN', 'cLFTC.ThCtAB.MEAN', 'LFTC.ThCtAB.MEAN',\n",
    "    'cMF.ThCtAB.MEAN', 'MT.ThCtAB.MEAN', 'cMFTC.ThCtAB.MEAN', 'MFTC.ThCtAB.MEAN',\n",
    "    \n",
    "    'LT.ThCcAB.MEAN', 'MT.ThCcAB.MEAN', 'cMF.ThCcAB.MEAN', 'cLF.ThCcAB.MEAN',\n",
    ")\n",
    "\n",
    "comparisons = [\n",
    "    ((4, ), (2, ), '000m', '012m'),\n",
    "    ((4, ), (2, ), '000m', '024m'),\n",
    "    ((3, 4), (1, 2), '000m', '012m'),\n",
    "    ((3, 4), (1, 2), '000m', '024m'),\n",
    "]\n",
    "\n",
    "for comparison in comparisons:\n",
    "    cases_ctr, cases_aff, visit_base, visit_cont = comparison\n",
    "    \n",
    "    dict_res = defaultdict(list)\n",
    "    \n",
    "    # Select subject groups: control and case, baseline and continuation\n",
    "    sel_ctr_base = df_tmp[df_tmp['CASE'].isin(cases_ctr) & (df_tmp['visit'] == visit_base)]\n",
    "    sel_ctr_cont = df_tmp[df_tmp['CASE'].isin(cases_ctr) & (df_tmp['visit'] == visit_cont)]\n",
    "    sel_aff_base = df_tmp[df_tmp['CASE'].isin(cases_aff) & (df_tmp['visit'] == visit_base)]\n",
    "    sel_aff_cont = df_tmp[df_tmp['CASE'].isin(cases_aff) & (df_tmp['visit'] == visit_cont)]\n",
    "    \n",
    "    for feature_code in feature_codes:\n",
    "        author_list = (\"ours\", analysis[0])\n",
    "        \n",
    "        for author in author_list:\n",
    "            if f\"{feature_code}_{author}\" not in df_tmp.columns:\n",
    "                continue\n",
    "\n",
    "            val_ctr_base = np.asarray(sel_ctr_base[f'{feature_code}_{author}'].tolist())\n",
    "            val_ctr_cont = np.asarray(sel_ctr_cont[f'{feature_code}_{author}'].tolist())\n",
    "            val_aff_base = np.asarray(sel_aff_base[f'{feature_code}_{author}'].tolist())\n",
    "            val_aff_cont = np.asarray(sel_aff_cont[f'{feature_code}_{author}'].tolist())\n",
    "\n",
    "            diff_ctr = val_ctr_base - val_ctr_cont\n",
    "            diff_aff = val_aff_base - val_aff_cont\n",
    "            \n",
    "            X = [*diff_ctr, *diff_aff]\n",
    "            y_true = [0, ] * len(diff_ctr) + [1, ] * len(diff_aff)\n",
    "            \n",
    "            X = np.asarray(X)\n",
    "            y_true = np.asarray(y_true)\n",
    "            sel = np.invert(np.isnan(X))\n",
    "            X = X[sel][..., None]\n",
    "            y_true = y_true[sel]\n",
    "\n",
    "            clf = sklearn.linear_model.LogisticRegression(penalty='none',\n",
    "                                                          class_weight='balanced',\n",
    "                                                          solver='newton-cg')\n",
    "            clf.fit(X, y_true)\n",
    "            y_pred = clf.predict(X)\n",
    "            \n",
    "            cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "            odds_ratio, pvalue = stats.fisher_exact(cm)\n",
    "\n",
    "            if pvalue < 0.05:\n",
    "                print(feature_code, author)\n",
    "\n",
    "            dict_res['feature_code'].append(feature_code)\n",
    "            dict_res['author'].append(author)\n",
    "\n",
    "            dict_res['odds_ratio'].append(odds_ratio)\n",
    "            dict_res['pvalue'].append(f\"{pvalue:0.3f}\")\n",
    "\n",
    "    df_res = pd.DataFrame.from_dict(dict_res)\n",
    "    display(df_res)\n",
    "\n",
    "    path_out = Path(f\"/home/egor/Workspace/proj_scartan/results/t/\"\n",
    "                    f\"csvs_{analysis[0]}_{analysis[1]}\")\n",
    "    path_out.mkdir(exist_ok=True)\n",
    "    \n",
    "    str_ctr = \"\".join(str(e) for e in cases_ctr)\n",
    "    str_aff = \"\".join(str(e) for e in cases_aff)\n",
    "\n",
    "    df_res.to_csv(Path(\n",
    "        path_out, f\"{str_ctr}vs{str_aff}_{visit_base}-{visit_cont}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# KL-wise profiling of ORs\n",
    "\n",
    "# Odds ratio\n",
    "\n",
    "# INFO: Choose one\n",
    "# analysis = (\"biomediq\", \"\")\n",
    "# analysis = (\"chondr\", \"elastic_lt\")\n",
    "analysis = (\"chondr\", \"elastic_dt\")\n",
    "\n",
    "\n",
    "if analysis[0] == \"biomediq\":\n",
    "    k = ('ours', 'biomediq')\n",
    "elif analysis[0] == \"chondr\":\n",
    "    k = ('ours', 'chondr75n')\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "df_sel_cmp = asmts_compare[k]\n",
    "\n",
    "if analysis[0] == \"biomediq\":\n",
    "    feature_codes = (\n",
    "        'F.VC', 'LF.VC', 'MF.VC',\n",
    "        'LT.VC', 'MT.VC',\n",
    "        'P.VC',\n",
    "        'LM.VC', 'MM.VC',\n",
    "    )\n",
    "elif analysis[0] == \"chondr\":\n",
    "    feature_codes = (\n",
    "    'cLF.VC', 'cMF.VC',\n",
    "    'LT.VC', 'MT.VC',\n",
    "    'ecLF.ThCtAB.MEAN', 'ccLF.ThCtAB.MEAN', 'icLF.ThCtAB.MEAN',\n",
    "    'ecMF.ThCtAB.MEAN', 'ccMF.ThCtAB.MEAN', 'icMF.ThCtAB.MEAN',\n",
    "    'aLT.ThCtAB.MEAN', 'iLT.ThCtAB.MEAN', 'cLT.ThCtAB.MEAN', 'pLT.ThCtAB.MEAN', 'eLT.ThCtAB.MEAN',\n",
    "    'aMT.ThCtAB.MEAN', 'iMT.ThCtAB.MEAN', 'cMT.ThCtAB.MEAN', 'pMT.ThCtAB.MEAN', 'eMT.ThCtAB.MEAN',\n",
    "    'cLF.ThCtAB.MEAN', 'LT.ThCtAB.MEAN', 'cLFTC.ThCtAB.MEAN', 'LFTC.ThCtAB.MEAN',\n",
    "    'cMF.ThCtAB.MEAN', 'MT.ThCtAB.MEAN', 'cMFTC.ThCtAB.MEAN', 'MFTC.ThCtAB.MEAN',\n",
    "    \n",
    "    'LT.ThCcAB.MEAN', 'MT.ThCcAB.MEAN', 'cMF.ThCcAB.MEAN', 'cLF.ThCcAB.MEAN',\n",
    ")\n",
    "\n",
    "comparisons = [\n",
    "    ((4, ), (2, ), '000m', '012m'),\n",
    "    ((4, ), (2, ), '000m', '024m'),\n",
    "    ((3, 4), (1, 2), '000m', '012m'),\n",
    "    ((3, 4), (1, 2), '000m', '024m'),\n",
    "]\n",
    "\n",
    "for kl in (\"all\", 1, 2, 3):\n",
    "    df_tmp = df_sel_cmp.copy()\n",
    "    \n",
    "    # Select subject by KL-grade\n",
    "    if kl == \"all\":\n",
    "        pass\n",
    "    else:\n",
    "        df_tmp = df_tmp[df_tmp[\"V00XRKL\"] == kl]\n",
    "    \n",
    "    for comparison in comparisons:\n",
    "        cases_ctr, cases_aff, visit_base, visit_cont = comparison\n",
    "\n",
    "        dict_res = defaultdict(list)\n",
    "\n",
    "        # Select subject groups: control and case, baseline and continuation\n",
    "        sel_ctr_base = df_tmp[df_tmp['CASE'].isin(cases_ctr) & (df_tmp['visit'] == visit_base)]\n",
    "        sel_ctr_cont = df_tmp[df_tmp['CASE'].isin(cases_ctr) & (df_tmp['visit'] == visit_cont)]\n",
    "        sel_aff_base = df_tmp[df_tmp['CASE'].isin(cases_aff) & (df_tmp['visit'] == visit_base)]\n",
    "        sel_aff_cont = df_tmp[df_tmp['CASE'].isin(cases_aff) & (df_tmp['visit'] == visit_cont)]\n",
    "        \n",
    "        print(f\"{kl}\")\n",
    "        print(len(sel_ctr_base), len(sel_aff_base))\n",
    "\n",
    "        for feature_code in feature_codes:\n",
    "            author_list = (\"ours\", analysis[0])\n",
    "        \n",
    "            for author in author_list:\n",
    "                if f\"{feature_code}_{author}\" not in df_tmp.columns:\n",
    "                    continue\n",
    "\n",
    "                val_ctr_base = np.asarray(sel_ctr_base[f'{feature_code}_{author}'].tolist())\n",
    "                val_ctr_cont = np.asarray(sel_ctr_cont[f'{feature_code}_{author}'].tolist())\n",
    "                val_aff_base = np.asarray(sel_aff_base[f'{feature_code}_{author}'].tolist())\n",
    "                val_aff_cont = np.asarray(sel_aff_cont[f'{feature_code}_{author}'].tolist())\n",
    "                \n",
    "                diff_ctr = val_ctr_base - val_ctr_cont\n",
    "                diff_aff = val_aff_base - val_aff_cont\n",
    "\n",
    "                X = [*diff_ctr, *diff_aff]\n",
    "                y_true = [0, ] * len(diff_ctr) + [1, ] * len(diff_aff)\n",
    "\n",
    "                X = np.asarray(X)\n",
    "                y_true = np.asarray(y_true)\n",
    "                sel = np.invert(np.isnan(X))\n",
    "                X = X[sel][..., None]\n",
    "                y_true = y_true[sel]\n",
    "\n",
    "                clf = sklearn.linear_model.LogisticRegression(penalty='none',\n",
    "                                                              class_weight='balanced',\n",
    "                                                              solver='newton-cg')\n",
    "                clf.fit(X, y_true)\n",
    "                y_pred = clf.predict(X)\n",
    "\n",
    "                cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "                odds_ratio, pvalue = stats.fisher_exact(cm)\n",
    "\n",
    "                if pvalue < 0.05:\n",
    "                    print(feature_code, author)\n",
    "\n",
    "                dict_res['feature_code'].append(feature_code)\n",
    "                dict_res['author'].append(author)\n",
    "\n",
    "                dict_res['odds_ratio'].append(odds_ratio)\n",
    "                dict_res['pvalue'].append(f\"{pvalue:0.3f}\")\n",
    "                dict_res['KL'] = kl\n",
    "\n",
    "        df_res = pd.DataFrame.from_dict(dict_res)\n",
    "        display(df_res)\n",
    "\n",
    "        path_out = Path(f\"/home/egor/Workspace/proj_scartan/results/t/\"\n",
    "                    f\"csvs_{analysis[0]}_{analysis[1]}\")\n",
    "        path_out.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        str_ctr = \"\".join(str(e) for e in cases_ctr)\n",
    "        str_aff = \"\".join(str(e) for e in cases_aff)\n",
    "\n",
    "        df_res.to_csv(Path(\n",
    "            path_out, f\"{str_ctr}vs{str_aff}_{visit_base}-{visit_cont}-{kl}.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
